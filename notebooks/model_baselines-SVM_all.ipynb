{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5102516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "Finished Loading...\n"
     ]
    }
   ],
   "source": [
    "from dataset_slide import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c165fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_order = {'F1_Interaction_1': {'P2': 1, 'P1': 1, 'P3': 2},\n",
    " 'F1_Interaction_2': {'P2': 1, 'P1': 1, 'P3': 2},\n",
    " 'F2_Interaction_1': {'P4': 1, 'P5': 3},\n",
    " 'F2_Interaction_2': {'P4': 1},\n",
    " 'F3_Interaction_1': {'P8': 3, 'P6': 1, 'P7': 1},\n",
    " 'F3_Interaction_2': {'P6': 1, 'P7': 1},\n",
    " 'F4_Interaction_1': {'P14': 2,\n",
    "  'P12': 1,\n",
    "  'P11': 1,\n",
    "  'P10': 1,\n",
    "  'P9': 1,\n",
    "  'P13': 3},\n",
    " 'F4_Interaction_2': {'P12': 1,\n",
    "  'P11': 1,\n",
    "  'P10': 1,\n",
    "  'P9': 1,\n",
    "  'P13': 3},\n",
    " 'F5_Interaction_1': {'P16': 2, 'P15': 1},\n",
    " 'F5_Interaction_2': {'P16': 2, 'P15': 1},\n",
    " 'F6_Interaction_1': {'P19': 3, 'P18': 1, 'P17': 1},\n",
    " 'F6_Interaction_2': {'P19': 3, 'P18': 1, 'P17': 1},\n",
    " 'F7_Interaction_1': {'P22': 3,\n",
    "  'P20': 1,\n",
    "  'P21': 1,\n",
    "  'P23': 2},\n",
    " 'F8_Interaction_1': {'P24': 1, 'P25': 3},\n",
    " 'F8_Interaction_2': {'P24': 1, 'P25': 3},\n",
    " 'F8_Interaction_3': {'P24': 1, 'P25': 3},\n",
    " 'F10_Interaction_1': {'P27': 1, 'P28': 1},\n",
    " 'F11_Interaction_1': {'P29': 1, 'P30': 2},\n",
    " 'F11_Interaction_2': {'P29': 1, 'P30': 2},\n",
    " 'F13_Interaction_1': {'P32': 1, 'P33': 2},\n",
    " 'F17_Interaction_1': {'P37': 1, 'P38': 2},\n",
    " 'F17_Interaction_2': {'P37': 1, 'P38': 2}}\n",
    "\n",
    "\n",
    "group_nums = {1: ['F2_Interaction_2'],\n",
    " 2: ['F2_Interaction_1',\n",
    "  'F3_Interaction_2',\n",
    "  'F5_Interaction_1',\n",
    "  'F5_Interaction_2',\n",
    "  'F8_Interaction_1',\n",
    "  'F8_Interaction_2',\n",
    "  'F8_Interaction_3',\n",
    "  'F10_Interaction_1',\n",
    "  'F11_Interaction_1',\n",
    "  'F11_Interaction_2',\n",
    "  'F13_Interaction_1',\n",
    "  'F17_Interaction_1',\n",
    "  'F17_Interaction_2'],\n",
    " 3: ['F1_Interaction_1',\n",
    "  'F1_Interaction_2',\n",
    "  'F3_Interaction_1',\n",
    "  'F6_Interaction_1',\n",
    "  'F6_Interaction_2'],\n",
    " 4: ['F7_Interaction_1'],\n",
    " 5: ['F4_Interaction_2'],\n",
    " 6: ['F4_Interaction_1']}\n",
    "\n",
    "group_all_dataset = []\n",
    "group_ids = group_nums[3]\n",
    "for group_id in group_ids:\n",
    "    group_specific_dataset = SpeedDatingDS(group_id = group_id, social_rel = person_order[group_id])\n",
    "    group_all_dataset.append(group_specific_dataset)\n",
    "\n",
    "SD = torch.utils.data.ConcatDataset(group_all_dataset)\n",
    "\n",
    "########################################################################\n",
    "#Dataloader\n",
    "########################################################################\n",
    "train_len = len(SD) - len(SD)//5\n",
    "val_len = len(SD)//10 + 1\n",
    "test_len = len(SD)//10\n",
    "\n",
    "train, val, test = torch.utils.data.random_split(SD, (train_len, val_len, test_len), generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "trainloader = DataLoader(train, batch_size = train_len, shuffle = True, num_workers = 8)\n",
    "valloader = DataLoader(val, batch_size = val_len, shuffle = True, num_workers = 8)\n",
    "testloader = DataLoader(test, batch_size = test_len, shuffle = True, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ffd2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for idx, batch in enumerate(trainloader):\n",
    "\n",
    "    x_train, vb_output = batch['context'], batch['vb_output']\n",
    "\n",
    "    labels = vb_output.sum(2).to(device).flatten(start_dim =1)\n",
    "    index_labels = torch.zeros(x_train.shape[0]).long().to(device)\n",
    "    index_labels[labels.nonzero()[:,0]] = labels.nonzero()[:,1] + 1 \n",
    "    y_train = index_labels\n",
    "\n",
    "for idx, batch in enumerate(testloader):\n",
    "    x_test, vb_output = batch['context'], batch['vb_output']\n",
    "\n",
    "    labels = vb_output.sum(2).to(device).flatten(start_dim =1)\n",
    "    index_labels = torch.zeros(x_test.shape[0]).long().to(device)\n",
    "    index_labels[labels.nonzero()[:,0]] = labels.nonzero()[:,1] + 1 \n",
    "    y_test = index_labels\n",
    "\n",
    "for idx, batch in enumerate(valloader):\n",
    "    x_val, vb_output = batch['context'], batch['vb_output']\n",
    "\n",
    "    labels = vb_output.sum(2).to(device).flatten(start_dim =1)\n",
    "    index_labels = torch.zeros(x_val.shape[0]).long().to(device)\n",
    "    index_labels[labels.nonzero()[:,0]] = labels.nonzero()[:,1] + 1 \n",
    "    y_val = index_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da0bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train.flatten(start_dim =1).cpu().numpy()\n",
    "y = y_train.cpu().numpy()\n",
    "\n",
    "x_test = x_test.flatten(start_dim =1).cpu().numpy()\n",
    "y_test = y_test.cpu().numpy()\n",
    "\n",
    "x_val = x_val.flatten(start_dim =1).cpu().numpy()\n",
    "y_val = y_val.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "349ae8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.233 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.233 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.233 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.233 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.233 (+/-0.000) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.233 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.316 (+/-0.054) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.233 (+/-0.000) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.287 (+/-0.052) for {'C': 1, 'kernel': 'linear'}\n",
      "0.345 (+/-0.063) for {'C': 10, 'kernel': 'linear'}\n",
      "0.343 (+/-0.068) for {'C': 100, 'kernel': 'linear'}\n",
      "0.342 (+/-0.067) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.233 (+/-0.000) for {'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.233 (+/-0.000) for {'gamma': 'auto', 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel':['sigmoid'], 'gamma':[\"auto\"]},\n",
    "                     {'kernel':['poly'], 'gamma':[\"auto\"]}\n",
    "                   ]\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e08b961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[281   0   1   0]\n",
      " [  8   2   0   0]\n",
      " [ 22   1   3   2]\n",
      " [  9   0   0   3]]\n",
      "f1: 0.4454220753596609\n",
      "acc: 0.8704819277108434\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel = 'linear', C = 10)\n",
    "\n",
    "svclassifier.fit(x, y)# Make prediction\n",
    "y_pred = svclassifier.predict(x_test)# Evaluate our model\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"f1: {}\".format(sklearn.metrics.f1_score(y_pred, y_test, average='macro')))\n",
    "print(\"acc: {}\".format((y_pred == y_test).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1748eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
