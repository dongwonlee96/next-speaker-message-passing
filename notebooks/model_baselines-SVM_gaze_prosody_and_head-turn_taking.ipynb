{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5102516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "Finished Loading...\n"
     ]
    }
   ],
   "source": [
    "from dataset_slide_turn_change import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c165fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_order = {'F1_Interaction_1': {'P2': 1, 'P1': 1, 'P3': 2},\n",
    " 'F1_Interaction_2': {'P2': 1, 'P1': 1, 'P3': 2},\n",
    " 'F2_Interaction_1': {'P4': 1, 'P5': 3},\n",
    " 'F2_Interaction_2': {'P4': 1},\n",
    " 'F3_Interaction_1': {'P8': 3, 'P6': 1, 'P7': 1},\n",
    " 'F3_Interaction_2': {'P6': 1, 'P7': 1},\n",
    " 'F4_Interaction_1': {'P14': 2,\n",
    "  'P12': 1,\n",
    "  'P11': 1,\n",
    "  'P10': 1,\n",
    "  'P9': 1,\n",
    "  'P13': 3},\n",
    " 'F4_Interaction_2': {'P12': 1,\n",
    "  'P11': 1,\n",
    "  'P10': 1,\n",
    "  'P9': 1,\n",
    "  'P13': 3},\n",
    " 'F5_Interaction_1': {'P16': 2, 'P15': 1},\n",
    " 'F5_Interaction_2': {'P16': 2, 'P15': 1},\n",
    " 'F6_Interaction_1': {'P19': 3, 'P18': 1, 'P17': 1},\n",
    " 'F6_Interaction_2': {'P19': 3, 'P18': 1, 'P17': 1},\n",
    " 'F7_Interaction_1': {'P22': 3,\n",
    "  'P20': 1,\n",
    "  'P21': 1,\n",
    "  'P23': 2},\n",
    " 'F8_Interaction_1': {'P24': 1, 'P25': 3},\n",
    " 'F8_Interaction_2': {'P24': 1, 'P25': 3},\n",
    " 'F8_Interaction_3': {'P24': 1, 'P25': 3},\n",
    " 'F10_Interaction_1': {'P27': 1, 'P28': 1},\n",
    " 'F11_Interaction_1': {'P29': 1, 'P30': 2},\n",
    " 'F11_Interaction_2': {'P29': 1, 'P30': 2},\n",
    " 'F13_Interaction_1': {'P32': 1, 'P33': 2},\n",
    " 'F17_Interaction_1': {'P37': 1, 'P38': 2},\n",
    " 'F17_Interaction_2': {'P37': 1, 'P38': 2}}\n",
    "\n",
    "\n",
    "group_nums = {1: ['F2_Interaction_2'],\n",
    " 2: ['F2_Interaction_1',\n",
    "  'F3_Interaction_2',\n",
    "  'F5_Interaction_1',\n",
    "  'F5_Interaction_2',\n",
    "  'F8_Interaction_1',\n",
    "  'F8_Interaction_2',\n",
    "  'F8_Interaction_3',\n",
    "  'F10_Interaction_1',\n",
    "  'F11_Interaction_1',\n",
    "  'F11_Interaction_2',\n",
    "  'F13_Interaction_1',\n",
    "  'F17_Interaction_1',\n",
    "  'F17_Interaction_2'],\n",
    " 3: ['F1_Interaction_1',\n",
    "  'F1_Interaction_2',\n",
    "  'F3_Interaction_1',\n",
    "  'F6_Interaction_1',\n",
    "  'F6_Interaction_2'],\n",
    " 4: ['F7_Interaction_1'],\n",
    " 5: ['F4_Interaction_2'],\n",
    " 6: ['F4_Interaction_1']}\n",
    "\n",
    "group_all_dataset = []\n",
    "group_ids = group_nums[3]\n",
    "for group_id in group_ids:\n",
    "    group_specific_dataset = SpeedDatingDS(group_id = group_id, social_rel = person_order[group_id])\n",
    "    group_all_dataset.append(group_specific_dataset)\n",
    "\n",
    "SD = torch.utils.data.ConcatDataset(group_all_dataset)\n",
    "\n",
    "########################################################################\n",
    "#Dataloader\n",
    "########################################################################\n",
    "train_len = len(SD) - len(SD)//5\n",
    "test_len = len(SD)//5\n",
    "\n",
    "train, test = torch.utils.data.random_split(SD, (train_len, test_len), generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train, batch_size = train_len, shuffle = True, num_workers = 8)\n",
    "testloader = DataLoader(test, batch_size = test_len, shuffle = True, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ffd2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for idx, batch in enumerate(trainloader):\n",
    "\n",
    "    x_train, vb_output = batch['context'], batch['vb_output']\n",
    "\n",
    "    labels = vb_output.sum(2).to(device).flatten(start_dim =1)\n",
    "    index_labels = torch.zeros(x_train.shape[0]).long().to(device)\n",
    "    index_labels[labels.nonzero()[:,0]] = labels.nonzero()[:,1] + 1 \n",
    "    y_train = index_labels\n",
    "\n",
    "for idx, batch in enumerate(testloader):\n",
    "    x_test, vb_output = batch['context'], batch['vb_output']\n",
    "\n",
    "    labels = vb_output.sum(2).to(device).flatten(start_dim =1)\n",
    "    index_labels = torch.zeros(x_test.shape[0]).long().to(device)\n",
    "    index_labels[labels.nonzero()[:,0]] = labels.nonzero()[:,1] + 1 \n",
    "    y_test = index_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da0bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x_train\n",
    "# y = y_train\n",
    "\n",
    "# x_test = x_test\n",
    "# y_test = y_test.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3aad2d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[...,desired_ind].flatten(start_dim =1).cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0773f706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.189 (+/-0.010) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.189 (+/-0.010) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.189 (+/-0.010) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.189 (+/-0.010) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.189 (+/-0.010) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.189 (+/-0.010) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.210 (+/-0.079) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.189 (+/-0.010) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.210 (+/-0.079) for {'C': 1, 'kernel': 'linear'}\n",
      "0.210 (+/-0.079) for {'C': 10, 'kernel': 'linear'}\n",
      "0.210 (+/-0.079) for {'C': 100, 'kernel': 'linear'}\n",
      "0.210 (+/-0.079) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.189 (+/-0.010) for {'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.189 (+/-0.010) for {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.210 (+/-0.079) for {'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 1000, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.189 (+/-0.010) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "f1: 0.1904761904761905\n",
      "f1_weighted: 0.5714285714285715\n",
      "acc: 0.4\n",
      "[[ 0 13  0]\n",
      " [ 0 14  0]\n",
      " [ 0  8  0]]\n"
     ]
    }
   ],
   "source": [
    "behavior_types = {\n",
    "    'Acknowledgement' : [*range(1,7)],\n",
    "    'Body' : [*range(7,14)],\n",
    "    'Head' : [*range(14, 20)],\n",
    "    'Hand' : [*range(20,22)],\n",
    "    'Eye' : [*range(22,25)],\n",
    "    'Face' : [*range(25,30)],\n",
    "    'Positive_Verbal' : [*range(30,35)],\n",
    "    'Negative_Verbal' : [*range(35,39)]} \n",
    "\n",
    "\n",
    "#mouth gape\n",
    "\n",
    "input_feats = 38\n",
    "desired_ind = [28]\n",
    "x_abl = x_train[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_abl = y_train.cpu().numpy()\n",
    "x_test_abl = x_test[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_test_abl = y_test.cpu().numpy()\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel':['sigmoid'], 'gamma':[\"auto\"]},\n",
    "                    {'kernel':['poly'], 'gamma':[1e-1 , 1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "                   ]\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(x_abl, y_abl)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_abl, clf.predict(x_test_abl)\n",
    "    print(\"f1: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='macro')))\n",
    "    print(\"f1_weighted: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='weighted')))\n",
    "    print(\"acc: {}\".format((y_pred == y_true).mean()))\n",
    "    print(confusion_matrix(y_test_abl, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b427a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.184 (+/-0.004) for {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.212 (+/-0.046) for {'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 1000, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.184 (+/-0.004) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "f1: 0.32639738882088937\n",
      "f1_weighted: 0.5385556915544676\n",
      "acc: 0.45714285714285713\n",
      "[[12  1  0]\n",
      " [10  4  0]\n",
      " [ 8  0  0]]\n"
     ]
    }
   ],
   "source": [
    "behavior_types = {\n",
    "    'Acknowledgement' : [*range(1,7)],\n",
    "    'Body' : [*range(7,14)],\n",
    "    'Head' : [*range(14, 20)],\n",
    "    'Hand' : [*range(20,22)],\n",
    "    'Eye' : [*range(22,25)],\n",
    "    'Face' : [*range(25,30)],\n",
    "    'Positive_Verbal' : [*range(30,35)],\n",
    "    'Negative_Verbal' : [*range(35,39)]} \n",
    "\n",
    "\n",
    "#head movement\n",
    "\n",
    "input_feats = 38\n",
    "desired_ind = [range(13,19)]\n",
    "x_abl = x_train[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_abl = y_train.cpu().numpy()\n",
    "x_test_abl = x_test[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_test_abl = y_test.cpu().numpy()\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "#                     {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel':['sigmoid'], 'gamma':[\"auto\"]},\n",
    "                     {'kernel':['poly'], 'gamma':[1e-1 , 1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "                   ]\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(x_abl, y_abl)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_abl, clf.predict(x_test_abl)\n",
    "    print(\"f1: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='macro')))\n",
    "    print(\"f1_weighted: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='weighted')))\n",
    "    print(\"acc: {}\".format((y_pred == y_true).mean()))\n",
    "    print(confusion_matrix(y_test_abl, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aac670cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.241 (+/-0.137) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.241 (+/-0.137) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.241 (+/-0.137) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.241 (+/-0.137) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.437 (+/-0.161) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.241 (+/-0.137) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.498 (+/-0.166) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.437 (+/-0.161) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.532 (+/-0.139) for {'C': 1, 'kernel': 'linear'}\n",
      "0.534 (+/-0.095) for {'C': 10, 'kernel': 'linear'}\n",
      "0.540 (+/-0.101) for {'C': 100, 'kernel': 'linear'}\n",
      "0.540 (+/-0.101) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.241 (+/-0.137) for {'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.219 (+/-0.095) for {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.325 (+/-0.087) for {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.457 (+/-0.156) for {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.482 (+/-0.186) for {'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 1000, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.219 (+/-0.095) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "f1: 0.4422413793103448\n",
      "f1_weighted: 0.4593103448275862\n",
      "acc: 0.45714285714285713\n",
      "[[5 4 4]\n",
      " [5 8 1]\n",
      " [2 3 3]]\n"
     ]
    }
   ],
   "source": [
    "behavior_types = {\n",
    "    'Acknowledgement' : [*range(1,7)],\n",
    "    'Body' : [*range(7,14)],\n",
    "    'Head' : [*range(14, 20)],\n",
    "    'Hand' : [*range(20,22)],\n",
    "    'Eye' : [*range(22,25)],\n",
    "    'Face' : [*range(25,30)],\n",
    "    'Positive_Verbal' : [*range(30,35)],\n",
    "    'Negative_Verbal' : [*range(35,39)]} \n",
    "\n",
    "\n",
    "#gaze, prosody, head\n",
    "\n",
    "input_feats = 38\n",
    "desired_ind = [*range(13,19)] + [*range(0,6)] + [*range(21,24)] + [*range(29,38)]\n",
    "x_abl = x_train[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_abl = y_train.cpu().numpy()\n",
    "x_test_abl = x_test[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_test_abl = y_test.cpu().numpy()\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel':['sigmoid'], 'gamma':[\"auto\"]},\n",
    "                     {'kernel':['poly'], 'gamma':[1e-1 , 1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "                   ]\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(x_abl, y_abl)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_abl, clf.predict(x_test_abl)\n",
    "    print(\"f1: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='macro')))\n",
    "    print(\"f1_weighted: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='weighted')))\n",
    "    print(\"acc: {}\".format((y_pred == y_true).mean()))\n",
    "    print(confusion_matrix(y_test_abl, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ae3611b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.250 (+/-0.164) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.164) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.164) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.164) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.599 (+/-0.242) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.164) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.626 (+/-0.050) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.599 (+/-0.242) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.608 (+/-0.105) for {'C': 1, 'kernel': 'linear'}\n",
      "0.629 (+/-0.090) for {'C': 10, 'kernel': 'linear'}\n",
      "0.619 (+/-0.096) for {'C': 100, 'kernel': 'linear'}\n",
      "0.619 (+/-0.096) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.250 (+/-0.164) for {'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.224 (+/-0.128) for {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.359 (+/-0.134) for {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.530 (+/-0.128) for {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.584 (+/-0.113) for {'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 1000, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.224 (+/-0.128) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "f1: 0.4953703703703704\n",
      "f1_weighted: 0.5132275132275133\n",
      "acc: 0.5142857142857142\n",
      "[[7 3 3]\n",
      " [4 8 2]\n",
      " [3 2 3]]\n"
     ]
    }
   ],
   "source": [
    "behavior_types = {\n",
    "    'Acknowledgement' : [*range(1,7)],\n",
    "    'Body' : [*range(7,14)],\n",
    "    'Head' : [*range(14, 20)],\n",
    "    'Hand' : [*range(20,22)],\n",
    "    'Eye' : [*range(22,25)],\n",
    "    'Face' : [*range(25,30)],\n",
    "    'Positive_Verbal' : [*range(30,35)],\n",
    "    'Negative_Verbal' : [*range(35,39)]} \n",
    "\n",
    "\n",
    "# all\n",
    "\n",
    "x_abl = x_train.flatten(start_dim =1).cpu().numpy()\n",
    "y_abl = y_train.cpu().numpy()\n",
    "x_test_abl = x_test.flatten(start_dim =1).cpu().numpy()\n",
    "y_test_abl = y_test.cpu().numpy()\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel':['sigmoid'], 'gamma':[\"auto\"]},\n",
    "                     {'kernel':['poly'], 'gamma':[1e-1 , 1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "                   ]\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(x_abl, y_abl)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_abl, clf.predict(x_test_abl)\n",
    "    print(\"f1: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='macro')))\n",
    "    print(\"f1_weighted: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='weighted')))\n",
    "    print(\"acc: {}\".format((y_pred == y_true).mean()))\n",
    "    print(confusion_matrix(y_test_abl, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908a780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
