{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5102516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "Finished Loading...\n"
     ]
    }
   ],
   "source": [
    "from dataset_slide import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c165fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_order = {'F1_Interaction_1': {'P2': 1, 'P1': 1, 'P3': 2},\n",
    " 'F1_Interaction_2': {'P2': 1, 'P1': 1, 'P3': 2},\n",
    " 'F2_Interaction_1': {'P4': 1, 'P5': 3},\n",
    " 'F2_Interaction_2': {'P4': 1},\n",
    " 'F3_Interaction_1': {'P8': 3, 'P6': 1, 'P7': 1},\n",
    " 'F3_Interaction_2': {'P6': 1, 'P7': 1},\n",
    " 'F4_Interaction_1': {'P14': 2,\n",
    "  'P12': 1,\n",
    "  'P11': 1,\n",
    "  'P10': 1,\n",
    "  'P9': 1,\n",
    "  'P13': 3},\n",
    " 'F4_Interaction_2': {'P12': 1,\n",
    "  'P11': 1,\n",
    "  'P10': 1,\n",
    "  'P9': 1,\n",
    "  'P13': 3},\n",
    " 'F5_Interaction_1': {'P16': 2, 'P15': 1},\n",
    " 'F5_Interaction_2': {'P16': 2, 'P15': 1},\n",
    " 'F6_Interaction_1': {'P19': 3, 'P18': 1, 'P17': 1},\n",
    " 'F6_Interaction_2': {'P19': 3, 'P18': 1, 'P17': 1},\n",
    " 'F7_Interaction_1': {'P22': 3,\n",
    "  'P20': 1,\n",
    "  'P21': 1,\n",
    "  'P23': 2},\n",
    " 'F8_Interaction_1': {'P24': 1, 'P25': 3},\n",
    " 'F8_Interaction_2': {'P24': 1, 'P25': 3},\n",
    " 'F8_Interaction_3': {'P24': 1, 'P25': 3},\n",
    " 'F10_Interaction_1': {'P27': 1, 'P28': 1},\n",
    " 'F11_Interaction_1': {'P29': 1, 'P30': 2},\n",
    " 'F11_Interaction_2': {'P29': 1, 'P30': 2},\n",
    " 'F13_Interaction_1': {'P32': 1, 'P33': 2},\n",
    " 'F17_Interaction_1': {'P37': 1, 'P38': 2},\n",
    " 'F17_Interaction_2': {'P37': 1, 'P38': 2}}\n",
    "\n",
    "\n",
    "group_nums = {1: ['F2_Interaction_2'],\n",
    " 2: ['F2_Interaction_1',\n",
    "  'F3_Interaction_2',\n",
    "  'F5_Interaction_1',\n",
    "  'F5_Interaction_2',\n",
    "  'F8_Interaction_1',\n",
    "  'F8_Interaction_2',\n",
    "  'F8_Interaction_3',\n",
    "  'F10_Interaction_1',\n",
    "  'F11_Interaction_1',\n",
    "  'F11_Interaction_2',\n",
    "  'F13_Interaction_1',\n",
    "  'F17_Interaction_1',\n",
    "  'F17_Interaction_2'],\n",
    " 3: ['F1_Interaction_1',\n",
    "  'F1_Interaction_2',\n",
    "  'F3_Interaction_1',\n",
    "  'F6_Interaction_1',\n",
    "  'F6_Interaction_2'],\n",
    " 4: ['F7_Interaction_1'],\n",
    " 5: ['F4_Interaction_2'],\n",
    " 6: ['F4_Interaction_1']}\n",
    "\n",
    "group_all_dataset = []\n",
    "group_ids = group_nums[3]\n",
    "for group_id in group_ids:\n",
    "    group_specific_dataset = SpeedDatingDS(group_id = group_id, social_rel = person_order[group_id])\n",
    "    group_all_dataset.append(group_specific_dataset)\n",
    "\n",
    "SD = torch.utils.data.ConcatDataset(group_all_dataset)\n",
    "\n",
    "########################################################################\n",
    "#Dataloader\n",
    "########################################################################\n",
    "train_len = len(SD) - len(SD)//5\n",
    "test_len = len(SD)//5\n",
    "\n",
    "train, test = torch.utils.data.random_split(SD, (train_len, test_len), generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(train, batch_size = train_len, shuffle = True, num_workers = 8)\n",
    "testloader = DataLoader(test, batch_size = test_len, shuffle = True, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ffd2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for idx, batch in enumerate(trainloader):\n",
    "\n",
    "    x_train, vb_output = batch['context'], batch['vb_output']\n",
    "\n",
    "    labels = vb_output.sum(2).to(device).flatten(start_dim =1)\n",
    "    index_labels = torch.zeros(x_train.shape[0]).long().to(device)\n",
    "    index_labels[labels.nonzero()[:,0]] = labels.nonzero()[:,1] + 1 \n",
    "    y_train = index_labels\n",
    "\n",
    "for idx, batch in enumerate(testloader):\n",
    "    x_test, vb_output = batch['context'], batch['vb_output']\n",
    "\n",
    "    labels = vb_output.sum(2).to(device).flatten(start_dim =1)\n",
    "    index_labels = torch.zeros(x_test.shape[0]).long().to(device)\n",
    "    index_labels[labels.nonzero()[:,0]] = labels.nonzero()[:,1] + 1 \n",
    "    y_test = index_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da0bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x_train\n",
    "# y = y_train\n",
    "\n",
    "# x_test = x_test\n",
    "# y_test = y_test.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04a1972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[...,desired_ind].flatten(start_dim =1).cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0773f706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.027 (+/-0.014) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.031 (+/-0.013) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.027 (+/-0.014) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.031 (+/-0.013) for {'C': 1, 'kernel': 'linear'}\n",
      "0.031 (+/-0.013) for {'C': 10, 'kernel': 'linear'}\n",
      "0.031 (+/-0.013) for {'C': 100, 'kernel': 'linear'}\n",
      "0.031 (+/-0.013) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.031 (+/-0.013) for {'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.031 (+/-0.013) for {'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1000, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "f1: 0.031469631646622795\n",
      "f1_weighted: 0.06151373896506639\n",
      "acc: 0.04360902255639098\n",
      "[[  7 571   0   0]\n",
      " [  0  21   0   0]\n",
      " [  0  48   1   0]\n",
      " [  0  17   0   0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "behavior_types = {\n",
    "    'Acknowledgement' : [*range(1,7)],\n",
    "    'Body' : [*range(7,14)],\n",
    "    'Head' : [*range(14, 20)],\n",
    "    'Hand' : [*range(20,22)],\n",
    "    'Eye' : [*range(22,25)],\n",
    "    'Face' : [*range(25,30)],\n",
    "    'Positive_Verbal' : [*range(30,35)],\n",
    "    'Negative_Verbal' : [*range(35,39)]} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_feats = 38\n",
    "\n",
    "#mouth gape\n",
    "desired_ind = [28]\n",
    "x_abl = x_train[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_abl = y_train.cpu().numpy()\n",
    "x_test_abl = x_test[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_test_abl = y_test.cpu().numpy()\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel':['sigmoid'], 'gamma':[\"auto\"]},\n",
    "                     {'kernel':['poly'], 'gamma':[1e-1 , 1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "                   ]\n",
    "\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "class_weight ={0:0.2858, 1: 7.0487, 2: 3.9988, 3: 9.1401}\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(class_weight = class_weight), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(x_abl, y_abl)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_abl, clf.predict(x_test_abl)\n",
    "    print(\"f1: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='macro')))\n",
    "    print(\"f1_weighted: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='weighted')))\n",
    "    print(\"acc: {}\".format((y_pred == y_true).mean()))\n",
    "    print(confusion_matrix(y_test_abl, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74d615ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.221 (+/-0.212) for {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.234 (+/-0.207) for {'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1000, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "f1: 0.35908141551071876\n",
      "f1_weighted: 0.8997779323782344\n",
      "acc: 0.8631578947368421\n",
      "[[565   3   9   1]\n",
      " [ 18   2   1   0]\n",
      " [ 44   0   5   0]\n",
      " [ 15   0   0   2]]\n"
     ]
    }
   ],
   "source": [
    "behavior_types = {\n",
    "    'Acknowledgement' : [*range(1,7)],\n",
    "    'Body' : [*range(7,14)],\n",
    "    'Head' : [*range(14, 20)],\n",
    "    'Hand' : [*range(20,22)],\n",
    "    'Eye' : [*range(22,25)],\n",
    "    'Face' : [*range(25,30)],\n",
    "    'Positive_Verbal' : [*range(30,35)],\n",
    "    'Negative_Verbal' : [*range(35,39)]} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_feats = 38\n",
    "\n",
    "\n",
    "#head physical\n",
    "\n",
    "desired_ind = [range(13,19)]\n",
    "x_abl = x_train[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_abl = y_train.cpu().numpy()\n",
    "x_test_abl = x_test[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_test_abl = y_test.cpu().numpy()\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "#                     {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel':['sigmoid'], 'gamma':[\"auto\"]},\n",
    "                     {'kernel':['poly'], 'gamma':[1e-1 , 1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "                   ]\n",
    "\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "class_weight ={0:0.2858, 1: 7.0487, 2: 3.9988, 3: 9.1401}\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(class_weight = class_weight), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(x_abl, y_abl)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_abl, clf.predict(x_test_abl)\n",
    "    print(\"f1: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='macro')))\n",
    "    print(\"f1_weighted: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='weighted')))\n",
    "    print(\"acc: {}\".format((y_pred == y_true).mean()))\n",
    "    print(confusion_matrix(y_test_abl, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "947c6842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.020 (+/-0.008) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.540 (+/-0.067) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.020 (+/-0.008) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.619 (+/-0.047) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.540 (+/-0.067) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.653 (+/-0.056) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.612 (+/-0.052) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.643 (+/-0.047) for {'C': 1, 'kernel': 'linear'}\n",
      "0.640 (+/-0.059) for {'C': 10, 'kernel': 'linear'}\n",
      "0.660 (+/-0.053) for {'C': 100, 'kernel': 'linear'}\n",
      "0.653 (+/-0.057) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.514 (+/-0.080) for {'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.312 (+/-0.157) for {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.644 (+/-0.050) for {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.689 (+/-0.054) for {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.702 (+/-0.042) for {'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.312 (+/-0.157) for {'C': 1000, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.017 (+/-0.004) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "f1: 0.6581939009751723\n",
      "f1_weighted: 0.8688011604907419\n",
      "acc: 0.8751879699248121\n",
      "[[527  14  24  13]\n",
      " [  2  17   0   2]\n",
      " [ 22   3  24   0]\n",
      " [  1   2   0  14]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "behavior_types = {\n",
    "    'Acknowledgement' : [*range(1,7)],\n",
    "    'Body' : [*range(7,14)],\n",
    "    'Head' : [*range(14, 20)],\n",
    "    'Hand' : [*range(20,22)],\n",
    "    'Eye' : [*range(22,25)],\n",
    "    'Face' : [*range(25,30)],\n",
    "    'Positive_Verbal' : [*range(30,35)],\n",
    "    'Negative_Verbal' : [*range(35,39)]} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_feats = 38\n",
    "\n",
    "#gaze, prosody, head\n",
    "\n",
    "\n",
    "desired_ind = [*range(13,19)] + [*range(0,6)] + [*range(21,24)] + [*range(29,38)]\n",
    "x_abl = x_train[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_abl = y_train.cpu().numpy()\n",
    "x_test_abl = x_test[...,desired_ind].flatten(start_dim =1).cpu().numpy()\n",
    "y_test_abl = y_test.cpu().numpy()\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel':['sigmoid'], 'gamma':[\"auto\"]},\n",
    "                     {'kernel':['poly'], 'gamma':[1e-1 , 1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "                   ]\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "class_weight ={0:0.2858, 1: 7.0487, 2: 3.9988, 3: 9.1401}\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(class_weight = class_weight), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(x_abl, y_abl)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_abl, clf.predict(x_test_abl)\n",
    "    print(\"f1: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='macro')))\n",
    "    print(\"f1_weighted: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='weighted')))\n",
    "    print(\"acc: {}\".format((y_pred == y_true).mean()))\n",
    "    print(confusion_matrix(y_test_abl, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "44a04b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.311 (+/-0.068) for {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.233 (+/-0.000) for {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.233 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.233 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.483 (+/-0.109) for {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.233 (+/-0.000) for {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.233 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.233 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.688 (+/-0.090) for {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.233 (+/-0.000) for {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.233 (+/-0.000) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.233 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "f1: 0.7251634413723698\n",
      "f1_weighted: 0.9272826135740136\n",
      "acc: 0.9203007518796993\n",
      "[[563   4   4   7]\n",
      " [ 11   9   1   0]\n",
      " [ 25   0  24   0]\n",
      " [  1   0   0  16]]\n"
     ]
    }
   ],
   "source": [
    "behavior_types = {\n",
    "    'Acknowledgement' : [*range(1,7)],\n",
    "    'Body' : [*range(7,14)],\n",
    "    'Head' : [*range(14, 20)],\n",
    "    'Hand' : [*range(20,22)],\n",
    "    'Eye' : [*range(22,25)],\n",
    "    'Face' : [*range(25,30)],\n",
    "    'Positive_Verbal' : [*range(30,35)],\n",
    "    'Negative_Verbal' : [*range(35,39)]} \n",
    "\n",
    "\n",
    "# all\n",
    "\n",
    "x_abl = x_train.flatten(start_dim =1).cpu().numpy()\n",
    "y_abl = y_train.cpu().numpy()\n",
    "x_test_abl = x_test.flatten(start_dim =1).cpu().numpy()\n",
    "y_test_abl = y_test.cpu().numpy()\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "#                     {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel':['sigmoid'], 'gamma':[\"auto\"]},\n",
    "                     {'kernel':['poly'], 'gamma':[1e-1 , 1e-2, 1e-3, 1e-4], 'C': [1, 10, 100]}\n",
    "                   ]\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(x_abl, y_abl)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_abl, clf.predict(x_test_abl)\n",
    "    print(\"f1: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='macro')))\n",
    "    print(\"f1_weighted: {}\".format(sklearn.metrics.f1_score(y_pred, y_true, average='weighted')))\n",
    "    print(\"acc: {}\".format((y_pred == y_true).mean()))\n",
    "    print(confusion_matrix(y_test_abl, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
